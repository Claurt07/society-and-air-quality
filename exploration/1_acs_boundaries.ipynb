{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitanaconda3virtualenv214083d9e99e48dbbb65188af8bf868a",
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ACS Boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step in this project is to take a look at what kind of regions we are looking at.\n",
    "\n",
    "We'll start off with CBSA boundaries, which are available from the official census.gov websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for downloading things\n",
    "import requests, zipfile, io\n",
    "def download_url(url, save_path):\n",
    "    r = requests.get(url)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with shapefiles\n",
    "import shapefile as shp # pip install pyshp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "env: GOOGLE_APPLICATION_CREDENTIALS=../google_app_credentials.json\n"
    }
   ],
   "source": [
    "# set up path to app credentials - see exploration/README.md\n",
    "%env GOOGLE_APPLICATION_CREDENTIALS=../google_app_credentials.json\n",
    "\n",
    "# set up bigquery client\n",
    "from google.cloud import bigquery\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have ACS data available from 2007 to 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n"
    }
   ],
   "source": [
    "resp = bq.query('''\n",
    "    SELECT DISTINCT do_date AS year\n",
    "    FROM `eosc410-project.data.acs_cbsa_*`\n",
    "    ORDER BY do_date ASC\n",
    "''')\n",
    "years = [row[\"year\"] for row in resp]\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can download all the boundary data from [census.gov](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "fetching \"https://www2.census.gov/geo/tiger/TIGER2007FE/fe_2007_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2007\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2008/tl_2008_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2008\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2009/tl_2009_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2009\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2010/CBSA/2010/tl_2010_us_cbsa10.zip\" to \"../docs/_datatmp/acs_cbsa_2010\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2011/CBSA/tl_2011_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2011\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2012/CBSA/tl_2012_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2012\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2013/CBSA/tl_2013_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2013\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2014/CBSA/tl_2014_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2014\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2015/CBSA/tl_2015_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2015\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2016/CBSA/tl_2016_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2016\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2017/CBSA/tl_2017_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2017\"\nfetching \"https://www2.census.gov/geo/tiger/TIGER2018/CBSA/tl_2018_us_cbsa.zip\" to \"../docs/_datatmp/acs_cbsa_2018\"\nDone!\n"
    }
   ],
   "source": [
    "for y in years:\n",
    "    save_to = '../docs/_datatmp/acs_cbsa_%s' % y\n",
    "\n",
    "    if y == '2007': # 2007 has a special format...\n",
    "        target = 'fe_%s_us_cbsa' % y\n",
    "        url = 'https://www2.census.gov/geo/tiger/TIGER%sFE/%s.zip' % (y, target)\n",
    "        print('fetching \"%s\" to \"%s\"' % (url, save_to))\n",
    "        download_url(url, save_to)\n",
    "    else:\n",
    "        target = 'tl_%s_us_cbsa' % y\n",
    "        if y == '2008' or y == '2009': # some random years have special formats too...\n",
    "            url = 'https://www2.census.gov/geo/tiger/TIGER%s/%s.zip' % (y, target)\n",
    "        elif y == '2010': # this single year has a slightly different path...\n",
    "            url = 'https://www2.census.gov/geo/tiger/TIGER2010/CBSA/2010/tl_2010_us_cbsa10.zip'\n",
    "        else:\n",
    "            url = 'https://www2.census.gov/geo/tiger/TIGER%s/CBSA/%s.zip' % (y, target)\n",
    "\n",
    "        print('fetching \"%s\" to \"%s\"' % (url, save_to))\n",
    "        try:\n",
    "            download_url(url, save_to)\n",
    "        except:\n",
    "            print('failed to fetch \"%s\"' % url)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we have here. CBSA boundaries shift from year to year, since they are regions anchored on \"urban centers\" of a certain number of people (see [definition](https://en.wikipedia.org/wiki/Core-based_statistical_area)), so let's make sure they look reasonable regardless and don't shift too dramatically so as to become very difficult to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12 years of data loaded\n2007 okay\n2008 okay\n2009 okay\n2010 okay\n2011 okay\n2012 okay\n2013 okay\n2014 okay\n2015 okay\n2016 okay\n2017 okay\n2018 okay\nall okay\n"
    }
   ],
   "source": [
    "def load_shapefile(y):\n",
    "    # random stackoverflow says these might be latin-1 encoding for some reason... it worked eh\n",
    "    # https://stackoverflow.com/questions/5552555/unicodedecodeerror-invalid-continuation-byte\n",
    "    if y == '2007':\n",
    "        return shp.Reader('../docs/_datatmp/acs_cbsa_2007/fe_2007_us_cbsa.shp', encoding='latin-1')\n",
    "    elif y == '2010':\n",
    "        # why??????\n",
    "        return shp.Reader('../docs/_datatmp/acs_cbsa_2010/tl_2010_us_cbsa10.shp', encoding='latin-1')\n",
    "    \n",
    "    return shp.Reader('../docs/_datatmp/acs_cbsa_%s/tl_%s_us_cbsa.shp' % (y, y), encoding='latin-1')\n",
    "\n",
    "# load years of shapes\n",
    "cbsa_years = [load_shapefile(y) for y in years]\n",
    "print(len(cbsa_years), 'years of data loaded')\n",
    "\n",
    "# test files\n",
    "i = 0\n",
    "for y in cbsa_years:\n",
    "    year = years[i]\n",
    "    try:\n",
    "        recs = y.shapeRecords()\n",
    "        print(year, 'okay')\n",
    "    except:\n",
    "        print(year, 'failed to load records')\n",
    "        print(sys.exc_info()[0])\n",
    "    i+=1\n",
    "print('all okay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cbsa_years' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7949ad4f4667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcbsa_year\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbsa_years\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plotting year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cbsa_years' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "plt.figure(figsize=(24,12))\n",
    "subplot = 0\n",
    "rows = 3\n",
    "columns = 4\n",
    "for cbsa_year in cbsa_years:\n",
    "    year = years[subplot]\n",
    "    print('plotting year', year)\n",
    "\n",
    "    plt.subplot(rows, columns, subplot+1)\n",
    "    for shape in cbsa_year.shapeRecords():\n",
    "        x = [i[0] for i in shape.shape.points[:]]\n",
    "        y = [i[1] for i in shape.shape.points[:]]\n",
    "        plt.plot(x,y)\n",
    "    plt.title(year)\n",
    "\n",
    "    subplot += 1\n",
    "\n",
    "print('all years plotted')\n",
    "plt.savefig('./figs/1/cbsa_all_years.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's dump this to some other formats to make it less painful to load. Forgot that [geopandas](https://geopandas.org/io.html) exists so we'll leverage that for the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-cac3695805a4>, line 28)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-cac3695805a4>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    print('Done!'): buffer}, indent=2) + \"\\n\")\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from json import dumps\n",
    "\n",
    "i = 0\n",
    "for reader in cbsa_years:\n",
    "    out = '../docs/_datatmp/acs_cbsa_%s/geojson.json' % years[i]\n",
    "\n",
    "    # adjusted from https://gist.github.com/agalea91/c0e0d1897d1d98a0029ac0baa02b9fca\n",
    "    fields = reader.fields[1:]\n",
    "    field_names = [field[0] for field in fields]\n",
    "    buffer = []\n",
    "    for sr in reader.shapeRecords():\n",
    "        record = sr.record\n",
    "        # Make sure everything is utf-8 compatable\n",
    "        record = [r.decode('utf-8', 'ignore') if isinstance(r, bytes) \n",
    "                  else r for r in record]\n",
    "        atr = dict(zip(field_names, record))\n",
    "        geom = sr.shape.__geo_interface__\n",
    "        buffer.append(dict(type=\"Feature\", geometry=geom, properties=atr)) \n",
    "\n",
    "    # write the GeoJSON file\n",
    "    if os.path.exists(out):\n",
    "        os.remove(out)\n",
    "    with open(out, \"w\") as geojson:\n",
    "        geojson.write(dumps({\"type\": \"FeatureCollection\", \"features\": buffer}) + \"\\n\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}